{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORcgW4dfbHFNJ7jAfQosGB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fgprevito/building-intuition/blob/main/Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OBJECTIVE:\n",
        "\n",
        "- Figure out how will we can explain how a company perofrms just by knowing company, sector, and year data.\n",
        "- Figure out what cross validation means in this context. What does it look like? How would that play out?\n",
        "- When we have a regression model, we'll read the outliers.\n",
        "\n",
        "Eventually we will try to get to a point where we need a LLM to interpret the results.\n"
      ],
      "metadata": {
        "id": "99goo8gbfPFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONTEXT:\n",
        "\n",
        "*\"There are few things which we know which aren't capable of being reduced to a mathematical reasoning. And when they cannot, it is a sign that our knowldge of them is very small and confused. Where a mathematic reasoning can be had, it is a great folly to make use of any other type of reasoning, as that would be like groping for a thing in the dark when you have a candle standing by you.\"*\n",
        "\n",
        "**Start with reverse engineering the data**\n",
        "\n",
        "I want to start by trying to solve for the following... There are 2 realities:\n",
        "\n",
        "  1: the model I have in mind makes sense\n",
        "\n",
        "  2: it doesn't\n",
        "\n",
        "Now, note that I'm not interested in getting into a philosophical debate about the linearity of companies. Let's just suppose a linear model can actually can explain data well. How do I know I'm actually explaining data well and not just fooling myself into these factors' relevancy? How do I tell difference beteen good explanations using models and bad explanations using models? Easiest way to do this is using 2 kinds of fake data:\n",
        "\n",
        "  1: Fake data that uses my model to make fake data\n",
        "\n",
        "  2: Fake data that obviously violates the assumptions of my model\n",
        "\n",
        "There are 2 parts to the model assumptions we've made:\n",
        "\n",
        "  (1) there are factors (companies belong in the secotrs, companies affected by year theyre in, etc).\n",
        "\n",
        "  (2) There's a small set of factors that added together, form estimates on how a company fairs.\n",
        "\n",
        "Fake data make most sense where we make up values for these different factors and add them up. Suppose we have factors that added up like this, does my model recover them? That's a sanity check. Reality for operation of companies is theyre extremely nonlinear due to inefficiencies (department rivalries, acquisitons). A human CEO will attempt as much as possible to atempt additive mentality though.\n",
        "\n",
        "    NOTE: Trying to learn math here!\n",
        "      If someone asks you for incredibly complicated model for stock prices you know they're morons\n",
        "      Do the assumptions of my model make sense with reality?\n",
        "      CFO enforces accounting view of additive cash flows to rationalize first order approximate answers\n",
        "      Long term successs wont be determined by this mentality though\n",
        "\n",
        "The other set of data need to totally violate my model assumptions (AKA make the data not related to each other). Ex.: truly independent random numbers. In this case my additive model should tell me I dont see the effect. I should see numbers that tell me there's no effect between my presumed causal mechanism and the metric I wish to optimize or phenomena I am attempting to understand.\n",
        "  \n",
        "NOTE: Your job isnt to find new variables, its to eliminate as many variables as you can from contention. This is the key to being a good quant: having an extremely disciplined process where you can eliminate irrelevant economic variables from contention\n",
        "\n",
        "So my objective here today is:\n",
        "\n",
        "- make fake data that actually models different things we've discussed\n",
        "\n",
        "  (1) what company am i\n",
        "\n",
        "  (2) what year is this\n",
        "\n",
        "  (3) sector\n",
        "\n",
        "  (4) outcome = what company am i in, what year am i in, sector\n",
        "\n",
        "  - how many comapny, year, sector factors do i have?\n",
        "\n",
        "    - make design matrix for that\n",
        "\n",
        "    - choose numbers for that\n",
        "    \n",
        "    - outcomes will be sums for this\n",
        "\n",
        "IMPORTANT:\n",
        " If I make data that are generated from an honest to God model, under what assumptions does my model recapitulate that structure? We should realize there are specific conditions where we can recapitulate that data. On what conditions can you invert the covariance matrix? What does it mean for matrix to be non singular? We want intuition for this. If data is truly driven from an additive process there are only certain conditions where these will be recovered\n",
        "\n",
        "Know how to make data to truly understand how to manipulate the processes (do i actually know what I think I'm doing? Even though fake data wont model reality exactly its good to know what parts of reality I cant control (Ex. are my models sensitive to one time deviations to the way things work?)\n",
        "\n",
        "Now, why did we pick pharma to start? Because people forget this a lot. If you think you are smart you should be doing something that on the margin creates additonal cash productivity, better mgmt, etc. You need to do something more than everyone else. I have a suspicion that pharma as an industry has been flatlined on return on research. It would be interesting if when we adjust for year-wise & macroeconomic affects, the industry is flatlined. Means we've lost imagination and need to think different. All goes back to rationalizng with fake data that we know how this simple world works\n"
      ],
      "metadata": {
        "id": "f3eto5yUe8qK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqgOkqX_iUlw"
      },
      "outputs": [],
      "source": [
        "# importing basic libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by setting some constant variables. It's important that models\n",
        " should be DYNAMIC and easy for the end user to interact with and stress test.\n",
        " Anyone that gives you a complicated model with no way to easily stress test\n",
        " it is a moron."
      ],
      "metadata": {
        "id": "nF20GsM3hZUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "\n",
        "STOCK_PRICE_MAX = 100\n",
        "NOISE_SCALE = 5"
      ],
      "metadata": {
        "id": "yg4_PmsinXd3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created a list of companies and then created a data dictionary that\n",
        " designated an integer value for each of my companies\n",
        " we did this so that I can run the numbers through my design matrix"
      ],
      "metadata": {
        "id": "pfkpfY2Uhfsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Company = ['Apple', 'Tesla', 'Microsoft', 'Amazon', 'Avronna', 'Novartis', 'Merck', 'Shell', 'Exxon', 'Chevron']\n",
        "co_map = {x:ii for (ii,x) in enumerate(Company)}\n",
        "print(co_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMuytwBjiW_0",
        "outputId": "e8ac78dc-1efa-41c5-86e0-36d6a220706e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Apple': 0, 'Tesla': 1, 'Microsoft': 2, 'Amazon': 3, 'Avronna': 4, 'Novartis': 5, 'Merck': 6, 'Shell': 7, 'Exxon': 8, 'Chevron': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created an empty list and called it acc\n",
        " for a range of years, we will select one company per each year\n",
        " selected co will be 1 non selected co for that year will remain 0"
      ],
      "metadata": {
        "id": "G_gKM4FLhnHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = []\n",
        "\n",
        "for yy in range(2008, 2008+5):\n",
        "  for c in Company:\n",
        "    new_row = np.zeros((len(Company), ))\n",
        "    new_row[co_map[c]] = 1\n",
        "    acc.append(new_row)"
      ],
      "metadata": {
        "id": "YIE_aTakihgL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " np.vstack will stack our arrays we've just written vertically.\n",
        "\n",
        "- basically, with our for loop, within the range of years we selected (number of times we want to reiterate through each company) we ran another for loop that iterates through each company in our comapny list\n",
        "- first with our company we create a list of 0s the length of the number of companies in our list\n",
        "- when we reach the company we currently are iterating through, we set it = to 1\n",
        "- we append that row to our empty list 'acc' and then go to the next company in the same year\n",
        "- once we iterate through all teh companies we move on to the next year and do the same\n",
        "\n",
        "We should expect, for 10 companies over 5 years, that we get an array that has 50 rows and 10 columns. Our number of columns was set to a length equalling the number of companies, since after we iterate through 10 companies in 1 year we then move on to the next and go through the 10 companies again\n",
        "\n",
        "Since we iterate through 10 companies 5 times, we should end up with 50 rows, 5 years of data for each of our 10 companies"
      ],
      "metadata": {
        "id": "BpJs_bb8huAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "design = np.vstack(acc)\n",
        "design"
      ],
      "metadata": {
        "id": "7a33YBXij8Iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d9286b-01a9-4028-fd77-191acb2b0314"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking shape of design just to make sure\n",
        "\n",
        "design.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA4bns73kdec",
        "outputId": "6aa90294-fd3d-43d9-e14d-9c9e343e3f22"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to create our coefficients (weights). This is how our predictor variables will relate to our result variables. We can multiply it by stock price max so we could get some more realistic values between 0 and 100."
      ],
      "metadata": {
        "id": "bXN_AGK0iK6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fake_weights = np.random.rand(design.shape[1]) * STOCK_PRICE_MAX\n",
        "fake_weights = np.random.rand(design.shape[1])"
      ],
      "metadata": {
        "id": "1uNXOzZDkmDw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions to consider now: What are our fake weights? Why did we get these weights? where did they come from? How were they generated?"
      ],
      "metadata": {
        "id": "DbemBjf9iaDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh8LC0AqkwFt",
        "outputId": "38af8909-5787-4252-9403-171f62dedaf0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.28992593, 0.69090884, 0.44452577, 0.64322638, 0.38844958,\n",
              "       0.46328897, 0.32833659, 0.69038083, 0.86734067, 0.44231478])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we take the dot product of our design matrix by our fake_weights to give the predicted values of our response var for each observations"
      ],
      "metadata": {
        "id": "-k5dmnjKigro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_outcomes = np.dot(design, fake_weights)"
      ],
      "metadata": {
        "id": "VfuPaX9XkxPY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating random data for me to predict here.\n",
        "\n",
        "Right now the data is generated from 0-1. In order to make the data more symmetrical we subtract .5 so it goes from -.5 to .5\n",
        "\n",
        "The noise is our error term, increasing variance and unpredictability"
      ],
      "metadata": {
        "id": "QeGU1NHpijqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fake_outcomes += (np.random.rand(fake_outcomes.shape[0]) - 0.5 ) * NOISE_SCALE\n",
        "fake_outcomes += np.random.rand(fake_outcomes.shape[0])"
      ],
      "metadata": {
        "id": "G-UyClA5mwJZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.rand(fake_outcomes.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbg7TBtqpuf-",
        "outputId": "ed83b366-4c96-42b4-9501-a294051f556e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.54808492, 0.64958869, 0.87584047, 0.00098975, 0.59399307,\n",
              "       0.43443394, 0.25699806, 0.14373301, 0.67525752, 0.93749254,\n",
              "       0.5372618 , 0.7046891 , 0.31172198, 0.46741913, 0.87989553,\n",
              "       0.81501497, 0.96660296, 0.4303964 , 0.55326329, 0.17446244,\n",
              "       0.69354458, 0.03627493, 0.92620906, 0.17228107, 0.00565652,\n",
              "       0.94818161, 0.69949637, 0.19891525, 0.16867032, 0.25251965,\n",
              "       0.06197036, 0.89146483, 0.1230127 , 0.47883486, 0.75677126,\n",
              "       0.20076339, 0.10294996, 0.32155852, 0.73099331, 0.35757569,\n",
              "       0.71235392, 0.26979955, 0.78102174, 0.77650829, 0.58259371,\n",
              "       0.00945105, 0.08444184, 0.82748878, 0.49025149, 0.9618718 ])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_outcomes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd0W7WSQoLSx",
        "outputId": "3e9b739f-143f-4c37-b180-9b08ec575a7c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.4490108 , 1.75880293, 0.82436732, 1.81095628, 1.04873819,\n",
              "       1.25513262, 2.01350524, 1.61032802, 1.91150101, 2.23715016,\n",
              "       1.39193599, 1.95790215, 0.95906701, 1.50661333, 1.97291801,\n",
              "       1.2613812 , 0.68900081, 1.16367761, 1.66390574, 1.31595947,\n",
              "       0.53705748, 1.27889843, 1.75747066, 2.2185214 , 1.47239134,\n",
              "       1.0924999 , 1.44801788, 2.24347254, 1.88727146, 1.89973669,\n",
              "       1.20052488, 1.08671895, 1.91196315, 1.43211632, 1.74205744,\n",
              "       1.6017717 , 0.87649482, 1.45273695, 1.85312556, 1.55638486,\n",
              "       1.57164858, 1.56391411, 1.74890826, 1.07879779, 1.45205429,\n",
              "       1.56635566, 2.16957958, 1.82202852, 1.98337291, 1.3422022 ])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this gives us the fake outcome for every tenth value in our matrix (Apple||0)\n",
        "\n",
        "fake_outcomes[::len(Company)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoQFJytnolO2",
        "outputId": "35798b7d-f450-46fc-da70-bfd6e20a3a6f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.4490108 , 1.39193599, 0.53705748, 1.20052488, 1.57164858])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the average of the predicted values for y when company is Apple?\n",
        "\n",
        "np.mean(fake_outcomes[::len(Company)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12KeofXLotE4",
        "outputId": "fc3a3375-99d6-4c6f-bd3a-bd7b070a4e39"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2300355454929357"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using linear reg library for now but will do it manually later"
      ],
      "metadata": {
        "id": "APgpTAKrm74T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "E0SWumTmlOBN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mylr = LinearRegression()"
      ],
      "metadata": {
        "id": "ehfQGDKOlwDK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mylr.fit(design, fake_outcomes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "04Rha3t0l1D9",
        "outputId": "61bd7eea-3104-4fbb-81e3-f7d77eb02262"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_outcomes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J4wZXxRtmI-",
        "outputId": "6287a0b3-8dbd-4b88-f5e5-d6ca7d7d4c31"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mylr.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo3PUtVRl4qm",
        "outputId": "dccd1877-3452-41a9-f540-9de892a076c9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.30296342, -0.00375165, -0.09264368,  0.07640206,  0.00463289,\n",
              "       -0.17757075, -0.0936793 ,  0.12544976,  0.32683637,  0.13728771])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mylr.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2VcybOVl7R7",
        "outputId": "0f8ce8fe-8438-4fed-e762-a02a0964b1d7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5329989640440693"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mylr.coef_ + mylr.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KscGMR6mAjF",
        "outputId": "6301baf9-7d53-4242-d6d3-7574b5b1633f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.23003555, 1.52924732, 1.44035528, 1.60940102, 1.53763185,\n",
              "       1.35542821, 1.43931967, 1.65844873, 1.85983534, 1.67028668])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we just did:\n",
        "- we had repeated obs for each company a number of times\n",
        "- we perfectly modeled the world as something evident\n",
        "- there was only one factor called company, no random noise\n",
        "- what linear regression does is subtract average value of outcome and fits intercept to that\n",
        "- intercept is something that takes care of \"how much do i get for free?\""
      ],
      "metadata": {
        "id": "DoCNZ1eamJ7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mylr = LinearRegression(fit_intercept=False)\n",
        "\n",
        "mylr.fit(design, fake_outcomes)\n",
        "\n",
        "mylr.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz_QLV_TmFen",
        "outputId": "940d0daa-1c51-4dfd-a0b9-3f4447deeb91"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.23003555, 1.52924732, 1.44035528, 1.60940102, 1.53763185,\n",
              "       1.35542821, 1.43931967, 1.65844873, 1.85983534, 1.67028668])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interecept is 0 because we said dont fit it\n",
        "- dont fit intercept means dont pretend you get values for free\n"
      ],
      "metadata": {
        "id": "GHwerk8rmqCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mylr.coef_ - fake_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTBWiX42mmRc",
        "outputId": "afdaa6dd-85b1-4764-a450-572b07ddd511"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.94010961, 0.83833847, 0.99582952, 0.96617464, 1.14918228,\n",
              "       0.89213924, 1.11098308, 0.9680679 , 0.99249467, 1.2279719 ])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_outcomes.reshape(5, len(Company))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vHcd_Lio6xe",
        "outputId": "f31966e8-424f-49c1-b28f-5d32810f5517"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4490108 , 1.75880293, 0.82436732, 1.81095628, 1.04873819,\n",
              "        1.25513262, 2.01350524, 1.61032802, 1.91150101, 2.23715016],\n",
              "       [1.39193599, 1.95790215, 0.95906701, 1.50661333, 1.97291801,\n",
              "        1.2613812 , 0.68900081, 1.16367761, 1.66390574, 1.31595947],\n",
              "       [0.53705748, 1.27889843, 1.75747066, 2.2185214 , 1.47239134,\n",
              "        1.0924999 , 1.44801788, 2.24347254, 1.88727146, 1.89973669],\n",
              "       [1.20052488, 1.08671895, 1.91196315, 1.43211632, 1.74205744,\n",
              "        1.6017717 , 0.87649482, 1.45273695, 1.85312556, 1.55638486],\n",
              "       [1.57164858, 1.56391411, 1.74890826, 1.07879779, 1.45205429,\n",
              "        1.56635566, 2.16957958, 1.82202852, 1.98337291, 1.3422022 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(fake_outcomes.reshape(5, len(Company)), axis = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzLDcTWspI9j",
        "outputId": "ad1a074e-dc0e-45c0-d562-6160c80537ee"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.23003555, 1.52924732, 1.44035528, 1.60940102, 1.53763185,\n",
              "       1.35542821, 1.43931967, 1.65844873, 1.85983534, 1.67028668])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Why are these numbers the same as my linear regression coef?"
      ],
      "metadata": {
        "id": "fdGIvhdTpt46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next: we will make copy of this and add a year factor\n",
        "- years will be shared for everyone (2008 is same 2008 for everyone)"
      ],
      "metadata": {
        "id": "uQpN6WUKpx3M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJ2sePD5pcqR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}