{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fgprevito/building-intuition/blob/main/Ridge_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSqjE08u01i4"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "# Download files from my computer\n",
        "from google.colab import files\n",
        "# Allows me to manage file related input and output operations\n",
        "# ex. reading or writing to files\n",
        "import io\n",
        "\n",
        "# Pandas provides data structures to let me work with relational or labeled data\n",
        "# In this case I can transform the google sheet data into a pandas dataframe I can work with\n",
        "import pandas\n",
        "\n",
        "# For matrix algebra and other mathematic operations that I'll need to do on\n",
        "# my dataset, I will import numpy, since it specializes in allowing me to work\n",
        "# with multi-dimsensional arary objects and providing fucntions/mathematical\n",
        "# tools for working with these arrays\n",
        "import numpy\n",
        "\n",
        "# For visualizing results/data points, I'll use matplotlib, since it\n",
        "# specializes in creating various types of visualizations\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# In order to handle the Ridge regression CV\n",
        "# sklearn specializes in implementing ML models and statistical\n",
        "# models like ridge regressions. RidgeCV library which will give me ridge regression functionality with cross validation built in.\n",
        "# train_test_split will help me split arrays into trainng and testing data sets automatically.\n",
        "# mean_squared_error is to evaluate MSE, while numpy can cover the rest of the evaluation criteria\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a function that makes a fake \"spreadsheet\" (as a dataframe)"
      ],
      "metadata": {
        "id": "AnMLgJn1-80f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fake spreadsheet in so-called \"long\" format\n",
        "# each row will have a company, a sector, a year, and some value (like net operating capital or some shit)\n",
        "\n",
        "def half_of_fake_spreadsheet(NUM_SECTORS, NUM_COMPANIES_PER_SECTOR, START_YEAR, NUM_YEARS):\n",
        "  # NUM_SECTORS = 4\n",
        "  # NUM_COMPANIES_PER_SECTOR = 3\n",
        "  # START_YEAR = 2017\n",
        "  # NUM_YEARS = 3\n",
        "\n",
        "  snames = ['Sector'+str(x) for x in range(NUM_SECTORS)]\n",
        "  cnames = [['FakeCo'+str(x)+'-'+sector_name for x in range(NUM_COMPANIES_PER_SECTOR)] for sector_name in snames]\n",
        "  cnames = [item for sublist in cnames for item in sublist]\n",
        "\n",
        "  rows = []\n",
        "  for cc in cnames:\n",
        "    implied_sector = cc.split('-')[1]\n",
        "    for yy in range(NUM_YEARS):\n",
        "      rows.append([cc, implied_sector, START_YEAR + yy])\n",
        "\n",
        "  df = pandas.DataFrame(data=rows, columns=['Company Name', 'Sector', 'Year'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "0NlrIlTy55af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = half_of_fake_spreadsheet(NUM_SECTORS=4, NUM_COMPANIES_PER_SECTOR=3, START_YEAR=2017, NUM_YEARS=3)\n",
        "# now I need another kind function to make up fake return values for those company / year combos"
      ],
      "metadata": {
        "id": "zbKEWhxl7urP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def companies_only_affects(df, NOISE_LEVEL=0):\n",
        "  company_levels = { x : ii for (ii,x) in enumerate(df['Company Name'].unique()) }\n",
        "  company_level_values = numpy.random.rand(len(company_levels))\n",
        "  # company_levels, company_level_values\n",
        "\n",
        "  plain_company_returns = numpy.array([company_level_values[company_levels[x]] for x in df['Company Name']])\n",
        "  noisy_company_returns = plain_company_returns + NOISE_LEVEL * numpy.random.randn(plain_company_returns.shape[0])\n",
        "  df['Return'] = noisy_company_returns\n",
        "  return df"
      ],
      "metadata": {
        "id": "8iOhFbhJ8TNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def companies_and_sector_affects(df, NOISE_LEVEL=0):\n",
        "  company_levels = { x : ii for (ii,x) in enumerate(df['Company Name'].unique()) }\n",
        "  company_level_values = numpy.random.rand(len(company_levels))\n",
        "\n",
        "  sector_levels = { x : ii for (ii,x) in enumerate(df['Sector'].unique()) }\n",
        "  sector_level_values = numpy.random.rand(len(sector_levels))\n",
        "\n",
        "  plain_company_returns = numpy.array([company_level_values[company_levels[x]] for x in df['Company Name']])\n",
        "  plain_sector_returns = numpy.array([sector_level_values[sector_levels[x]] for x in df['Sector']])\n",
        "\n",
        "  noisy_returns = plain_company_returns + plain_sector_returns + NOISE_LEVEL * numpy.random.randn(plain_company_returns.shape[0])\n",
        "  df['Return'] = noisy_returns\n",
        "  return df"
      ],
      "metadata": {
        "id": "hveqvVrI98lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Company+Sector+Year affects outcome\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yQyOi0ByH3xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_spreadsheet = companies_and_sector_affects(df, NOISE_LEVEL=0)"
      ],
      "metadata": {
        "id": "CgHMCsVO98jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_spreadsheet = fake_spreadsheet"
      ],
      "metadata": {
        "id": "7poOSSAk98gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_company_design(the_spreadsheet):\n",
        "  unique_companies = { x : ii for (ii,x) in enumerate(the_spreadsheet['Company Name'].unique()) }\n",
        "\n",
        "  num_unique_companies = len(unique_companies)\n",
        "\n",
        "  design = numpy.zeros((the_spreadsheet.shape[0], num_unique_companies))\n",
        "  for ii, cn in enumerate(the_spreadsheet['Company Name']):\n",
        "    design[ii, unique_companies[cn]] = 1\n",
        "\n",
        "  return design"
      ],
      "metadata": {
        "id": "X7uf183z98e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "A design matrix is nothing but a landscape for me to record which factors affect which outcomes\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "YrHh5raGFR5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unique_companies = { x : ii for (ii,x) in enumerate(the_spreadsheet['Company Name'].unique()) }\n",
        "\n",
        "num_unique_companies = len(unique_companies)\n",
        "\n",
        "design = numpy.zeros((the_spreadsheet.shape[0], num_unique_companies))\n",
        "for ii, cn in enumerate(the_spreadsheet['Company Name']):\n",
        "  design[ii, unique_companies[cn]] = 1\n"
      ],
      "metadata": {
        "id": "kS6yxDltC2R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(the_spreadsheet.shape[])"
      ],
      "metadata": {
        "id": "e_UhP6T3_cNA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "b0d4c873-1b09-4b84-fe23-a22005b07e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-e431568cd6c0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(the_spreadsheet.shape[])\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSd3Bzr7_cKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNaLCF4k_cH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlLZaHEY_cE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a function that takes a dataframe -> makes a design matrix"
      ],
      "metadata": {
        "id": "ozcZIOpA5s_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE = 0\n",
        "SINGLE_CO_NOISE = 1\n",
        "START_YEAR = 2017\n",
        "NUM_YEARS = 2"
      ],
      "metadata": {
        "id": "Mo7RokBE1JEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "This next section I now generate the fake data.\n",
        "\n",
        "I need my companies to be associated to their respective sectors. I'm going to continue using the same method I've used to generate fake data which is to manually write it up inside of a list, generate a data dictionary for each list so that each value has a respective numeric representation, and then pass these numeric representations of my company, sector, year data into a set of arrays that I will combine to form a design matrix.\n",
        "\n",
        "The reason for this is I believe it'll be easier for me to modify the data if I would like to versus loading in a dataframe from google sheets.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Pz8VXcA5F4L9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "I have a list of companies alongside the sector they belong to. I want to be able to pass all this data in numeric form into a design matrix so that I can mathematically analyze it.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1wENTAAqG9b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of companies along with the sectors they belong to\n",
        "\n",
        "company_data = [('Apple', 'Tech'),('Microsoft', 'Tech'),('Amazon', 'Tech'),('Dell', 'Tech'),('Novartis', 'Pharma'),('Merck', 'Pharma'),('Alcon', 'Pharma'),('Abbvie', 'Pharma')]\n",
        "company_data"
      ],
      "metadata": {
        "id": "0X8_XvrSu_tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List comprehension: expression for element in iterable if condition\n",
        "# enumerate(company_data) for elements in company_data, enumerate each value\n",
        "# for ii,x in enumerate(company_data) then iterate through both the value and index pairs\n",
        "# {x:ii for ii,x in enumerate(company_data)} and the expression is creating a dictionary where they key is x and value is ii\n",
        "\n",
        "# AKA This is the expression i want performed for these iterable values in the element enumerate(company_data)\n",
        "\n",
        "company_map = {x: ii for ii,x in enumerate(company_data)}\n",
        "company_map"
      ],
      "metadata": {
        "id": "34Dt1Po8fpbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ditto\n",
        "\n",
        "year_data = numpy.arange(START_YEAR, START_YEAR + NUM_YEARS)\n",
        "year_map = {x:ii for ii,x in enumerate(year_data)}\n",
        "year_map"
      ],
      "metadata": {
        "id": "eUC1aENXY3qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Now that I have generated a set of fictitious data and married them to numeric values, I can create my design matrix. The method I will be using to create my design matrix is I can pass the numeric representatiosn of my fictitious data into a set of arrays that I can stack into a design matrix.\n",
        "\n",
        "Why am I building a design matrix?\n",
        "\n",
        "The design matrix is essentially a diagram that allows me to explain the outputs in terms of the inputs. so for each row I'll have a certain company, the sector it's in, and the year in which I am looking at this company and sector, and I can then chart this data directly to an output. Its basically the most simple way I can explain my outputs as a result of my inputs. Through this design matrix though, I'll be able to perform some more sophisticated analysis which I'll get to in a second.\n",
        "\n",
        "---\n",
        "\n",
        "So that's the theoretical/verbal description of how I will accomplish the creation of my design matrix but programmatically how can I accomplish this goal?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-sAQvXJ5wQOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an accumulator. The results from the following for loop logic will\n",
        "# be accumulated in this list before stacking them into a matrix format\n",
        "\n",
        "# for each year within the range selected through the constants START_YEAR and NUM_YEARS\n",
        "  # iterate through each row within company_map\n",
        "      # for each row in company_map create a row of zeros the length of the lists company_data and year_data\n",
        "      # we will use these rows of 0s as plceholders to store values\n",
        "\n",
        "      # for the iteration we are on, select that 0 and set it = 1\n",
        "      # ex. where c = 1, find the value at company_map = 1 and set that 0 in new_row to 1\n",
        "\n",
        "      # for the year iteration we are on, set that 0 = 1\n",
        "      # ex if yy = 1, find the value at year_map = 1 and set the corresponding space in\n",
        "      # new_row to 1 after passing a number of 0s equal to the length of company_data\n",
        "      # so if company_data has length of 8, first skip through 8 zeros, then begin selecting values for year\n",
        "\n",
        "      # append this new_row to the list acc\n",
        "\n",
        "# vertically concatonates the list of arrays stored in acc to form the\n",
        "# design matrix\n",
        "\n",
        "acc = []\n",
        "\n",
        "for yy in range(START_YEAR, START_YEAR + NUM_YEARS):\n",
        "    for c in company_map:\n",
        "      new_row = numpy.zeros(len(company_data) + len(year_data), )\n",
        "      new_row[company_map[c]] = 1\n",
        "      new_row[year_map[yy] + len(company_data)] = 1\n",
        "      acc.append(new_row)\n",
        "\n",
        "design_matrix = numpy.vstack(acc)\n",
        "design_matrix"
      ],
      "metadata": {
        "id": "0xm13n1lwHen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = []\n",
        "\n",
        "for yy in range(START_YEAR, START_YEAR + NUM_YEARS):\n",
        "  for c in company_data:\n",
        "    new_row = numpy.zeros(len(company_data) + len(year_data), )\n",
        "    new_row[company_map[c]] = 1\n",
        "    new_row[year_map[yy] + len(company_data)] = 1\n",
        "    acc.append(new_row)\n",
        "\n",
        "design_matrix = numpy.vstack(acc)\n",
        "design_matrix"
      ],
      "metadata": {
        "id": "pnL_Etj21PSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "First step in solving a problem is getting a lay of the land, figuring out what info I have at my disposal so that I can most effectively solve my problem of understanding the relationships between variables and predicting future observations. I know I'll be using matrix algebra to manipulate and analyze data so it's important I know the dimensions of my design matrix\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S1HPlifPNIEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identifying the shape of the deisgn matrix\n",
        "\n",
        "design_matrix.shape"
      ],
      "metadata": {
        "id": "nC3sXnfY1PQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "now I want know the rank of my matrix. This will give me an early check as to whether or not I have covariant data (essentially columns that may not necessarily be relevant to predicting stock price)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DoMGciGDNQI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating my deisng matrix' rank\n",
        "\n",
        "numpy.linalg.matrix_rank(design_matrix)"
      ],
      "metadata": {
        "id": "Fn4LudskuEux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "I can see it is rank deficient. When I worked with only 1 variable my matrix was full rank, but when I added a second variable my matrix rank was = n columns - 1. Now I have 3 variables and the matrix rank is = n columns - 2.\n",
        "\n",
        "Why is that?\n",
        "\n",
        "Rank deficiency effectively means I have insufficient information in my data to be able to estimate the model I desire.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Vfu_Kr1tNYCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the true relationship between variables I am trying to identify using\n",
        "# ridge regression cross validated\n",
        "\n",
        "actual_weights = numpy.random.rand(design_matrix.shape[1])\n",
        "actual_weights"
      ],
      "metadata": {
        "id": "luVZz99v1cCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating fictitious continuous financial output based on inputs times their\n",
        "# weights\n",
        "\n",
        "outcomes = numpy.dot(design_matrix, actual_weights)\n",
        "outcomes"
      ],
      "metadata": {
        "id": "slz7Yd2TOE-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding noise to the outcomes\n",
        "\n",
        "outcomes += (numpy.random.rand(outcomes.shape[0]) - .5) * NOISE\n",
        "outcomes"
      ],
      "metadata": {
        "id": "Qzgsvq881b_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding noise to a single outcome observation to simulate outliers\n",
        "\n",
        "outcomes[0] = outcomes[0] * SINGLE_CO_NOISE\n",
        "outcomes"
      ],
      "metadata": {
        "id": "0GJDoBztX43W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Covariance\n",
        "\n",
        "numpy.dot(design_matrix.T, design_matrix)"
      ],
      "metadata": {
        "id": "KiEuX2jbJfJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision\n",
        "\n",
        "numpy.linalg.pinv(numpy.dot(design_matrix.T, design_matrix))"
      ],
      "metadata": {
        "id": "cDKwr5nFJe7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hat\n",
        "\n",
        "numpy.dot(numpy.linalg.pinv(numpy.dot(design_matrix.T, design_matrix)), design_matrix.T)"
      ],
      "metadata": {
        "id": "HHEDDUQpJe20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Because I know I'm trying to predict some kind of continuous variable, this is the reason I have selected a regression model. The purpose for selecting a ridge regression model in particular is because it has the particular capability of being able to simplify complex relationships as something linear, improving my ability to interpret the relationships between my variables, while still retaining decently strong predictability.  \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ErApoi88Dcrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(design_matrix, outcomes, test_size=.3)\n",
        "\n",
        "# This is for special case for ridge regression\n",
        "X_train = design_matrix[1:]\n",
        "y_train = outcomes[1:]\n",
        "X_test = design_matrix[:1]\n",
        "y_test = outcomes[:1]\n",
        "\n",
        "ridge = RidgeCV(alphas=[.01, .1, 1.0, 10.0, 100.0], fit_intercept=False)\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge.coef_"
      ],
      "metadata": {
        "id": "PTUR4Sqy1b6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_outcomes = ridge.predict(X_test)\n",
        "pred_outcomes"
      ],
      "metadata": {
        "id": "P_U22ABA3DLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyplot.plot([0,1], [0,1], 'r-')\n",
        "pyplot.plot(actual_weights, ridge.coef_, 'k.')\n",
        "\n",
        "pyplot.xlabel('Actual Weights')\n",
        "pyplot.ylabel('Predicted Weights')"
      ],
      "metadata": {
        "id": "TG_tndj12vVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyplot.plot([0,1], [0,1], 'r-')\n",
        "pyplot.plot(y_test, pred_outcomes, 'k.')\n",
        "\n",
        "pyplot.xlabel('Actual Outcomes')\n",
        "pyplot.ylabel('Pred Outcomes')"
      ],
      "metadata": {
        "id": "VQexyGoh22zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE\n",
        "\n",
        "numpy.mean((pred_outcomes - y_test)**2)"
      ],
      "metadata": {
        "id": "Kvp63Lr2SvmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ME\n",
        "\n",
        "numpy.mean(actual_weights - ridge.coef_)"
      ],
      "metadata": {
        "id": "dIP8CcdFSvjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variance\n",
        "\n",
        "numpy.var(actual_weights - ridge.coef_)"
      ],
      "metadata": {
        "id": "VBSyo9jVSvg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Deviation\n",
        "\n",
        "numpy.std(actual_weights - ridge.coef_)"
      ],
      "metadata": {
        "id": "k3FvbZECSveg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Observations:\n",
        "\n",
        "When only adding noise to a single variable, Ridge does great job at identifying the true regression weights and not allowing the noisy variable to skew calculations.\n",
        "\n",
        "MSE seems to be worse at times? It could be because I'm effectively overfitting the OLS to the training data, so what I'm observing is the overfit model working better on the dataset I trained it on. Ridge should in theory be better able to predict future values as it's supposed to be better about not letting noisy variables affect it's ability to calculate the parameters.\n",
        "\n",
        "When I add a noisy variable to training data and set test data to be without noise, the difference was highlighted. Could see how OLS MSE was worse while Ridge kept its form.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We're still assuming that the relationship is linear, but Ridge is supposed to work better even if outcome is discrete or relationship between inputs and outputs is logarithmic. This leads me to believe regardless of the relationship Ridge shoud do at least a decent job at calculating parameters and predicting future observations.\n",
        "\n",
        "Shouldn't direclty inteerpret params as true relationshio due to lambda and model is less interpretable since ridge retains irrelevant columns.\n",
        "\n",
        "Can I still use Ridge to understand the relationship between data? Or is it mroe an answer to the fact that we can perfectly model the compelxity of the world so we created a hack to simplify the complexity?\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VyvQJkaEfk91"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIqdl_Vnm7d1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}